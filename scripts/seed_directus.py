#!/usr/bin/env python3
"""
Seed Directus collections with sample data from local CSV and API predictions.

Collections populated:
- planets: from data/data_set_final.csv (first 50 rows mapped)
- discoveries: synthetic entries for first 10 planets
- planet_flags: sample flags for first 5 planets for the admin user
- training_datasets: metadata for CSV
- training_runs: one synthetic completed run referencing dataset
- predictions: generated by calling API /api/v1/predict/batch using provided test payload

Environment variables (optional):
- DIRECTUS_URL (default http://localhost:8055)
- DIRECTUS_ADMIN_EMAIL (default admin@example.com)
- DIRECTUS_ADMIN_PASSWORD (default d1r3ctu5)
- API_URL (default http://localhost:8000)

Usage:
  python3 scripts/seed_directus.py
"""
import csv
import json
import os
import random
import time
from datetime import datetime, timezone
from pathlib import Path
from urllib import request, parse, error

ROOT = Path(__file__).resolve().parents[1]
CSV_PATH = ROOT / "data" / "data_set_final.csv"
TEST_PAYLOAD = ROOT / "apps" / "api" / "test_payloads" / "batch_mixed_all_classes.json"

DIRECTUS_URL = os.getenv("DIRECTUS_URL", "http://localhost:8055")
ADMIN_EMAIL = os.getenv("DIRECTUS_ADMIN_EMAIL", os.getenv("DIRECTUS_ADMIN"))
ADMIN_PASSWORD = os.getenv("DIRECTUS_ADMIN_PASSWORD", os.getenv("DIRECTUS_PASSWORD"))
API_URL = os.getenv("API_URL", "http://localhost:8000")

HEADERS_JSON = {"Content-Type": "application/json"}


def http(method: str, url: str, *, headers=None, data=None, timeout=30):
    body = None
    if data is not None:
        if isinstance(data, (dict, list)):
            body = json.dumps(data).encode("utf-8")
        elif isinstance(data, (bytes, bytearray)):
            body = data
        else:
            body = str(data).encode("utf-8")
    req = request.Request(url, data=body, method=method)
    for k, v in (headers or {}).items():
        req.add_header(k, v)
    with request.urlopen(req, timeout=timeout) as resp:
        ct = resp.headers.get("Content-Type", "")
        raw = resp.read()
        if "application/json" in ct:
            return json.loads(raw.decode("utf-8"))
        try:
            return json.loads(raw.decode("utf-8"))
        except Exception:
            return raw


def directus_login():
    url = f"{DIRECTUS_URL}/auth/login"
    payload = {"email": ADMIN_EMAIL, "password": ADMIN_PASSWORD}
    try:
        data = http("POST", url, headers=HEADERS_JSON, data=payload)
    except error.URLError as e:
        raise SystemExit(f"Failed to connect to Directus at {url}: {e}")
    access_token = data.get("data", {}).get("access_token") if isinstance(data, dict) else None
    if not access_token:
        raise SystemExit(f"Directus login failed: {data}")
    return access_token


def directus_get_me(token: str):
    url = f"{DIRECTUS_URL}/users/me"
    data = http("GET", url, headers={"Authorization": f"Bearer {token}"})
    uid = data.get("data", {}).get("id") if isinstance(data, dict) else None
    if not uid:
        raise SystemExit(f"Unable to fetch current user: {data}")
    return uid


def directus_create_items(token: str, collection: str, items):
    url = f"{DIRECTUS_URL}/items/{collection}"
    data = http(
        "POST",
        url,
        headers={"Authorization": f"Bearer {token}", **HEADERS_JSON},
        data=items,
    )
    return data


def read_csv_planets(max_rows=50):
    if not CSV_PATH.exists():
        raise SystemExit(f"CSV not found at {CSV_PATH}")
    rows = []
    with CSV_PATH.open(newline="", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for i, row in enumerate(reader):
            if i >= max_rows:
                break
            try:
                # Map and convert types
                disp_en = (row["disposition"] or "").strip().upper()
                disp_map = {
                    "CONFIRMED": "Planeta Confirmado",
                    "CANDIDATE": "Candidato",
                    "FALSE POSITIVE": "Falso Positivo",
                    "REFUTED": "Refutado",
                }
                disposicion = disp_map.get(disp_en, disp_en or "Candidato")
                rows.append({
                    "id_objeto": str(row["id_obj"]).strip(),
                    "disposicion": disposicion,
                    "radio_planeta": float(row["pl_rade"]) if row["pl_rade"] else None,
                    "temp_planeta": float(row["pl_eqt"]) if row["pl_eqt"] else None,
                    "periodo_orbital": float(row["pl_orbper"]) if row["pl_orbper"] else None,
                    "temp_estrella": float(row["st_teff"]) if row["st_teff"] else None,
                    "radio_estrella": float(row["st_rad"]) if row["st_rad"] else None,
                    "Loc1_RA": float(row["ra"]) if row["ra"] else None,
                    "Loc2_DEC": float(row["dec"]) if row["dec"] else None,
                    "dist": float(row["st_dist"]) if row["st_dist"] else None,
                    "status": "published",
                })
            except Exception:
                # Skip malformed
                continue
    return rows


def seed_planets(token: str, planets):
    # Bulk create in chunks
    CHUNK = 25
    created = []
    for i in range(0, len(planets), CHUNK):
        chunk = planets[i:i+CHUNK]
        resp = directus_create_items(token, "planets", chunk)
        created.extend(resp.get("data", []) if isinstance(resp, dict) else [])
    return created


def seed_discoveries(token: str, planet_items, user_id: str, count=10):
    now = datetime.now(timezone.utc).isoformat()
    items = []
    for p in planet_items[:count]:
        # synthetic geo + orientation
        lat = round(20.67 + random.uniform(-0.05, 0.05), 6)
        lng = round(-103.38 + random.uniform(-0.05, 0.05), 6)
        alpha = round(random.uniform(0, 360), 2)
        beta = round(random.uniform(-10, 60), 2)
        gamma = round(random.uniform(-30, 30), 2)
        items.append({
            "planet": p.get("id"),
            "user": user_id,
            "created_at": now,
            "lat": lat,
            "lng": lng,
            "alpha": alpha,
            "beta": beta,
            "gamma": gamma,
            "notes": f"Seed discovery for {p.get('id_objeto')}"
        })
    if not items:
        return []
    return directus_create_items(token, "discoveries", items).get("data", [])


def seed_flags(token: str, planet_items, user_id: str, count=5):
    items = []
    for i, p in enumerate(planet_items[:count]):
        items.append({
            "planet": p.get("id"),
            "user": user_id,
            "orbit": True,
            "alien": i % 2 == 0,
            "heart": i % 3 == 0,
            "created_at": datetime.now(timezone.utc).isoformat(),
            "pair_key": f"{p.get('id')}:{user_id}",
        })
    if not items:
        return []
    return directus_create_items(token, "planet_flags", items).get("data", [])


def seed_training_dataset(token: str, total_records: int):
    item = {
        "title": "TESS Final Dataset",
        "source": str(CSV_PATH.relative_to(ROOT)),
        "records_count": int(total_records),
        "description": "Sample dataset metadata from local CSV (file not imported)"
    }
    return directus_create_items(token, "training_datasets", item).get("data", {})


def seed_training_run(token: str, dataset_id: str):
    start = datetime.now(timezone.utc)
    end = start.replace(microsecond=0)
    duration = random.uniform(12.3, 45.8)
    item = {
        "dataset": dataset_id,
        "status": "completed",
        "started_at": start.isoformat(),
        "finished_at": end.isoformat(),
        "accuracy": round(random.uniform(0.82, 0.93), 4),
        "classification_report": {"Candidato": {"precision": 0.85}, "Planeta Confirmado": {"precision": 0.90}},
        "confusion_matrix": [[42, 8], [6, 47]],
        "features": ["pl_rade", "pl_eqt", "pl_orbper", "st_teff", "st_rad", "st_logg", "st_tmag", "ra", "dec", "st_dist"],
        "model_type": "LightGBM",
        "model_path": "models/exoplanets_lgbm_pipeline.joblib",
        "label_mapping": {"Candidato": 0, "Planeta Confirmado": 1, "Falso Positivo": 2, "Refutado": 3},
        "training_samples": 1200,
        "test_samples": 300,
        "duration_seconds": round(duration, 3),
    }
    return directus_create_items(token, "training_runs", item).get("data", {})


def try_seed_predictions(token: str):
    if not TEST_PAYLOAD.exists():
        return []
    try:
        with TEST_PAYLOAD.open("r", encoding="utf-8") as f:
            payload = json.load(f)
        candidates = payload.get("candidates", [])
        if not candidates:
            return []
        # Call API
        url = f"{API_URL}/api/v1/predict/batch"
        resp = http("POST", url, headers=HEADERS_JSON, data={"candidates": candidates})
        if not isinstance(resp, dict) or "predictions" not in resp:
            # API not available; skip
            return []
        preds = resp["predictions"]
        now = datetime.now(timezone.utc).isoformat()
        items = []
        for i, pred in enumerate(preds):
            cand = candidates[i]
            items.append({
                "planet": None,
                "input_features": cand,
                "predicted_label": pred.get("prediction"),
                "predicted_code": pred.get("prediction_code"),
                "probabilities": pred.get("probabilities"),
                "confidence": pred.get("confidence"),
                "timestamp": now,
                "source": "api"
            })
        created = directus_create_items(token, "predictions", items)
        return created.get("data", [])
    except Exception:
        return []


def main():
    print("Logging into Directus...", flush=True)
    token = "XK0JG9EjuKi2t7Wrz6XMbCOLR43vRHXB"
    user_id = directus_get_me(token)
    print(f"Logged in. user_id={user_id}")

    print(f"Reading CSV: {CSV_PATH}")
    planets = read_csv_planets(max_rows=50)
    print(f"Parsed planets: {len(planets)}")
    if planets:
        print("Creating planets...")
        created_planets = seed_planets(token, planets)
        print(f"Created planets: {len(created_planets)}")
    else:
        created_planets = []

    print("Creating discoveries...")
    disc = seed_discoveries(token, created_planets, user_id, count=min(10, len(created_planets)))
    print(f"Created discoveries: {len(disc)}")

    print("Creating planet flags...")
    flags = seed_flags(token, created_planets, user_id, count=min(5, len(created_planets)))
    print(f"Created flags: {len(flags)}")

    # Count total records in CSV
    total_records = sum(1 for _ in CSV_PATH.open("r", encoding="utf-8")) - 1
    print("Creating training dataset...")
    ds = seed_training_dataset(token, total_records)
    print(f"Created dataset id: {ds.get('id')}")

    if ds.get("id"):
        print("Creating training run...")
        run = seed_training_run(token, ds.get("id"))
        print(f"Created run id: {run.get('id')}")

    print("Generating predictions from API (if available)...")
    preds = try_seed_predictions(token)
    print(f"Created predictions: {len(preds)}")

    print("Done.")


if __name__ == "__main__":
    main()
